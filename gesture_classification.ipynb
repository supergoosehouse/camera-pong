{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/gesture.csv'\n",
    "model_save_path = 'model/gesture_classifier/gesture_classifier.keras'\n",
    "tflite_save_path = 'model/gesture_classifier/gesture_classifier.tflite'\n",
    "labels = 'model/gesture_classifier_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_in_csv(filename):\n",
    "  total_words = 0\n",
    "  with open(filename, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "      # Count words in each row (assuming comma separation)\n",
    "      num_words = sum(1 for word in row if word.strip())  # Count non-empty words\n",
    "      total_words += num_words\n",
    "  return total_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = count_words_in_csv(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))\n",
    "#y = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))\n",
    "X = pd.read_csv(dataset, usecols=list(range(1, (21 * 2) + 1)))\n",
    "X.fillna(0, inplace=True)\n",
    "X = X.astype(float)\n",
    "\n",
    "y = pd.read_csv(dataset, usecols=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes):\n",
    "    inputs = keras.Input(shape=(21 * 2,))\n",
    "    x = keras.layers.Dropout(0.2)(inputs)\n",
    "    x = keras.layers.Dense(20, activation='relu')(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(10, activation='relu')(x)\n",
    "    outputs = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model = create_model(n_classes)  # Assuming n_classes is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m860\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,103</span> (4.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,103\u001b[0m (4.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,103</span> (4.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,103\u001b[0m (4.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - accuracy: 0.3516 - loss: 1.0974\n",
      "Epoch 1: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 472ms/step - accuracy: 0.3407 - loss: 1.0985 - val_accuracy: 0.1754 - val_loss: 1.1367\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3828 - loss: 1.1000\n",
      "Epoch 2: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3668 - loss: 1.1000 - val_accuracy: 0.2105 - val_loss: 1.1306\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3828 - loss: 1.1066\n",
      "Epoch 3: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3668 - loss: 1.1045 - val_accuracy: 0.2105 - val_loss: 1.1241\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3359 - loss: 1.0828\n",
      "Epoch 4: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3630 - loss: 1.0763 - val_accuracy: 0.2105 - val_loss: 1.1179\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4062 - loss: 1.0937\n",
      "Epoch 5: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4178 - loss: 1.0899 - val_accuracy: 0.2105 - val_loss: 1.1115\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3594 - loss: 1.0783\n",
      "Epoch 6: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3669 - loss: 1.0808 - val_accuracy: 0.2632 - val_loss: 1.1058\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3906 - loss: 1.0932\n",
      "Epoch 7: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3969 - loss: 1.0963 - val_accuracy: 0.2632 - val_loss: 1.1001\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3984 - loss: 1.0908\n",
      "Epoch 8: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3995 - loss: 1.0916 - val_accuracy: 0.2807 - val_loss: 1.0950\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3750 - loss: 1.0841\n",
      "Epoch 9: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.3838 - loss: 1.0795 - val_accuracy: 0.2807 - val_loss: 1.0906\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3516 - loss: 1.0851\n",
      "Epoch 10: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3642 - loss: 1.0835 - val_accuracy: 0.2807 - val_loss: 1.0862\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3906 - loss: 1.0996\n",
      "Epoch 11: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3851 - loss: 1.0922 - val_accuracy: 0.3158 - val_loss: 1.0819\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3438 - loss: 1.0958\n",
      "Epoch 12: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.3538 - loss: 1.0919 - val_accuracy: 0.3684 - val_loss: 1.0779\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3672 - loss: 1.0951\n",
      "Epoch 13: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3695 - loss: 1.0952 - val_accuracy: 0.3860 - val_loss: 1.0742\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4141 - loss: 1.0963\n",
      "Epoch 14: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.4204 - loss: 1.0888 - val_accuracy: 0.3860 - val_loss: 1.0711\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 1.0408\n",
      "Epoch 15: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.4882 - loss: 1.0463 - val_accuracy: 0.4211 - val_loss: 1.0677\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3594 - loss: 1.0744\n",
      "Epoch 16: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3747 - loss: 1.0664 - val_accuracy: 0.4386 - val_loss: 1.0643\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3516 - loss: 1.0824\n",
      "Epoch 17: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3642 - loss: 1.0770 - val_accuracy: 0.4386 - val_loss: 1.0610\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4453 - loss: 1.0526\n",
      "Epoch 18: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4543 - loss: 1.0514 - val_accuracy: 0.4737 - val_loss: 1.0576\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3750 - loss: 1.0689\n",
      "Epoch 19: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3760 - loss: 1.0737 - val_accuracy: 0.5263 - val_loss: 1.0539\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4297 - loss: 1.0601\n",
      "Epoch 20: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4373 - loss: 1.0576 - val_accuracy: 0.5439 - val_loss: 1.0504\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3906 - loss: 1.0636\n",
      "Epoch 21: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4243 - loss: 1.0536 - val_accuracy: 0.5789 - val_loss: 1.0463\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4922 - loss: 1.0480\n",
      "Epoch 22: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4660 - loss: 1.0520 - val_accuracy: 0.6140 - val_loss: 1.0422\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.3438 - loss: 1.0865\n",
      "Epoch 23: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.3656 - loss: 1.0799 - val_accuracy: 0.6491 - val_loss: 1.0384\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5391 - loss: 1.0194\n",
      "Epoch 24: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5287 - loss: 1.0185 - val_accuracy: 0.6667 - val_loss: 1.0340\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5391 - loss: 1.0273\n",
      "Epoch 25: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5169 - loss: 1.0354 - val_accuracy: 0.7018 - val_loss: 1.0291\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5156 - loss: 1.0370\n",
      "Epoch 26: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5327 - loss: 1.0309 - val_accuracy: 0.6842 - val_loss: 1.0239\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4297 - loss: 1.0339\n",
      "Epoch 27: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.4530 - loss: 1.0288 - val_accuracy: 0.7018 - val_loss: 1.0183\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5781 - loss: 1.0218\n",
      "Epoch 28: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5888 - loss: 1.0129 - val_accuracy: 0.7368 - val_loss: 1.0120\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4688 - loss: 1.0406\n",
      "Epoch 29: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4543 - loss: 1.0432 - val_accuracy: 0.7368 - val_loss: 1.0064\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4609 - loss: 1.0415\n",
      "Epoch 30: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4595 - loss: 1.0398 - val_accuracy: 0.7368 - val_loss: 1.0020\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4922 - loss: 1.0261\n",
      "Epoch 31: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.4935 - loss: 1.0247 - val_accuracy: 0.7368 - val_loss: 0.9981\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4922 - loss: 1.0409\n",
      "Epoch 32: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.4896 - loss: 1.0468 - val_accuracy: 0.7018 - val_loss: 0.9946\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4766 - loss: 1.0184\n",
      "Epoch 33: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4922 - loss: 1.0104 - val_accuracy: 0.7018 - val_loss: 0.9917\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4844 - loss: 0.9964\n",
      "Epoch 34: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4869 - loss: 1.0041 - val_accuracy: 0.7018 - val_loss: 0.9891\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5469 - loss: 0.9858\n",
      "Epoch 35: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5352 - loss: 0.9934 - val_accuracy: 0.6667 - val_loss: 0.9862\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5391 - loss: 1.0186\n",
      "Epoch 36: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5248 - loss: 1.0153 - val_accuracy: 0.7018 - val_loss: 0.9832\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4609 - loss: 1.0184\n",
      "Epoch 37: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.4438 - loss: 1.0234 - val_accuracy: 0.7193 - val_loss: 0.9806\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5234 - loss: 0.9917\n",
      "Epoch 38: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5274 - loss: 1.0014 - val_accuracy: 0.7368 - val_loss: 0.9780\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5391 - loss: 1.0214\n",
      "Epoch 39: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5444 - loss: 1.0138 - val_accuracy: 0.7368 - val_loss: 0.9754\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5312 - loss: 1.0147\n",
      "Epoch 40: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5143 - loss: 1.0136 - val_accuracy: 0.7544 - val_loss: 0.9728\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5703 - loss: 0.9994\n",
      "Epoch 41: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5627 - loss: 0.9983 - val_accuracy: 0.8070 - val_loss: 0.9708\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4609 - loss: 1.0233\n",
      "Epoch 42: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4831 - loss: 1.0202 - val_accuracy: 0.7895 - val_loss: 0.9687\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5156 - loss: 1.0096\n",
      "Epoch 43: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5091 - loss: 1.0126 - val_accuracy: 0.8070 - val_loss: 0.9662\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5703 - loss: 0.9819\n",
      "Epoch 44: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5823 - loss: 0.9765 - val_accuracy: 0.8246 - val_loss: 0.9632\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5312 - loss: 1.0252\n",
      "Epoch 45: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5183 - loss: 1.0177 - val_accuracy: 0.8421 - val_loss: 0.9598\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5078 - loss: 0.9850\n",
      "Epoch 46: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.5104 - loss: 0.9836 - val_accuracy: 0.8596 - val_loss: 0.9563\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5938 - loss: 0.9590\n",
      "Epoch 47: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6018 - loss: 0.9579 - val_accuracy: 0.8596 - val_loss: 0.9523\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5156 - loss: 1.0009\n",
      "Epoch 48: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5209 - loss: 0.9927 - val_accuracy: 0.8596 - val_loss: 0.9486\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5156 - loss: 1.0104\n",
      "Epoch 49: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5013 - loss: 1.0128 - val_accuracy: 0.8596 - val_loss: 0.9461\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6250 - loss: 0.9496\n",
      "Epoch 50: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6123 - loss: 0.9534 - val_accuracy: 0.8596 - val_loss: 0.9431\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5859 - loss: 0.9591\n",
      "Epoch 51: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5796 - loss: 0.9683 - val_accuracy: 0.8596 - val_loss: 0.9396\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5781 - loss: 0.9621\n",
      "Epoch 52: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5456 - loss: 0.9646 - val_accuracy: 0.8596 - val_loss: 0.9357\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6719 - loss: 0.9017\n",
      "Epoch 53: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6710 - loss: 0.9112 - val_accuracy: 0.8772 - val_loss: 0.9310\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5391 - loss: 0.9895\n",
      "Epoch 54: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.5562 - loss: 0.9896 - val_accuracy: 0.8772 - val_loss: 0.9259\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5234 - loss: 0.9808\n",
      "Epoch 55: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5274 - loss: 0.9749 - val_accuracy: 0.8772 - val_loss: 0.9209\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5547 - loss: 0.9421\n",
      "Epoch 56: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5457 - loss: 0.9553 - val_accuracy: 0.8772 - val_loss: 0.9167\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6250 - loss: 0.9640\n",
      "Epoch 57: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6044 - loss: 0.9665 - val_accuracy: 0.8772 - val_loss: 0.9128\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5781 - loss: 0.9336\n",
      "Epoch 58: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5653 - loss: 0.9423 - val_accuracy: 0.8772 - val_loss: 0.9091\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5469 - loss: 0.9786\n",
      "Epoch 59: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5431 - loss: 0.9817 - val_accuracy: 0.8772 - val_loss: 0.9061\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.5391 - loss: 0.9560\n",
      "Epoch 60: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5444 - loss: 0.9618 - val_accuracy: 0.8772 - val_loss: 0.9026\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5781 - loss: 0.9365\n",
      "Epoch 61: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5731 - loss: 0.9456 - val_accuracy: 0.8772 - val_loss: 0.8988\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6250 - loss: 0.9124\n",
      "Epoch 62: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6201 - loss: 0.9101 - val_accuracy: 0.8596 - val_loss: 0.8951\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6250 - loss: 0.9133\n",
      "Epoch 63: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6240 - loss: 0.9175 - val_accuracy: 0.8772 - val_loss: 0.8905\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6406 - loss: 0.9152\n",
      "Epoch 64: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6331 - loss: 0.9208 - val_accuracy: 0.8772 - val_loss: 0.8849\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5781 - loss: 0.9273\n",
      "Epoch 65: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.5692 - loss: 0.9387 - val_accuracy: 0.8772 - val_loss: 0.8791\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5391 - loss: 0.9301\n",
      "Epoch 66: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5405 - loss: 0.9279 - val_accuracy: 0.8772 - val_loss: 0.8733\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5703 - loss: 0.9598\n",
      "Epoch 67: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5744 - loss: 0.9458 - val_accuracy: 0.8772 - val_loss: 0.8668\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5625 - loss: 0.9314\n",
      "Epoch 68: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5914 - loss: 0.9172 - val_accuracy: 0.8947 - val_loss: 0.8594\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5938 - loss: 0.9151\n",
      "Epoch 69: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5979 - loss: 0.9127 - val_accuracy: 0.8772 - val_loss: 0.8516\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6250 - loss: 0.8785\n",
      "Epoch 70: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6279 - loss: 0.8838 - val_accuracy: 0.8947 - val_loss: 0.8439\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5859 - loss: 0.9060\n",
      "Epoch 71: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5718 - loss: 0.9074 - val_accuracy: 0.8947 - val_loss: 0.8368\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6250 - loss: 0.8701\n",
      "Epoch 72: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.6201 - loss: 0.8818 - val_accuracy: 0.8947 - val_loss: 0.8304\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6016 - loss: 0.9050\n",
      "Epoch 73: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6162 - loss: 0.8999 - val_accuracy: 0.8947 - val_loss: 0.8238\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6250 - loss: 0.8789\n",
      "Epoch 74: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6319 - loss: 0.8832 - val_accuracy: 0.8947 - val_loss: 0.8177\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5703 - loss: 0.8864\n",
      "Epoch 75: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5862 - loss: 0.8910 - val_accuracy: 0.8947 - val_loss: 0.8111\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5469 - loss: 0.8876\n",
      "Epoch 76: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5666 - loss: 0.8877 - val_accuracy: 0.8947 - val_loss: 0.8048\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6484 - loss: 0.8752\n",
      "Epoch 77: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6514 - loss: 0.8705 - val_accuracy: 0.8947 - val_loss: 0.7991\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6484 - loss: 0.8450\n",
      "Epoch 78: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6436 - loss: 0.8475 - val_accuracy: 0.8947 - val_loss: 0.7929\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6562 - loss: 0.8471\n",
      "Epoch 79: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6540 - loss: 0.8456 - val_accuracy: 0.8947 - val_loss: 0.7855\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6250 - loss: 0.8723\n",
      "Epoch 80: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.6319 - loss: 0.8709 - val_accuracy: 0.9123 - val_loss: 0.7769\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5938 - loss: 0.8386\n",
      "Epoch 81: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.5901 - loss: 0.8422 - val_accuracy: 0.9123 - val_loss: 0.7681\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6484 - loss: 0.8339\n",
      "Epoch 82: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6475 - loss: 0.8399 - val_accuracy: 0.9123 - val_loss: 0.7598\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6250 - loss: 0.8481\n",
      "Epoch 83: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6397 - loss: 0.8388 - val_accuracy: 0.9123 - val_loss: 0.7510\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.6484 - loss: 0.8443\n",
      "Epoch 84: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.6514 - loss: 0.8389 - val_accuracy: 0.9123 - val_loss: 0.7404\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6562 - loss: 0.7952\n",
      "Epoch 85: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6305 - loss: 0.8193 - val_accuracy: 0.9123 - val_loss: 0.7305\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6797 - loss: 0.7822\n",
      "Epoch 86: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6736 - loss: 0.7952 - val_accuracy: 0.9123 - val_loss: 0.7206\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6094 - loss: 0.8642\n",
      "Epoch 87: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6110 - loss: 0.8632 - val_accuracy: 0.9123 - val_loss: 0.7113\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6094 - loss: 0.8430\n",
      "Epoch 88: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6188 - loss: 0.8373 - val_accuracy: 0.9123 - val_loss: 0.7021\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6406 - loss: 0.8448\n",
      "Epoch 89: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6371 - loss: 0.8336 - val_accuracy: 0.9123 - val_loss: 0.6934\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6797 - loss: 0.7780\n",
      "Epoch 90: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6854 - loss: 0.7852 - val_accuracy: 0.9298 - val_loss: 0.6843\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6094 - loss: 0.8303\n",
      "Epoch 91: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6345 - loss: 0.8172 - val_accuracy: 0.9298 - val_loss: 0.6761\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6797 - loss: 0.7847\n",
      "Epoch 92: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6815 - loss: 0.7857 - val_accuracy: 0.9474 - val_loss: 0.6685\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7344 - loss: 0.7796\n",
      "Epoch 93: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7389 - loss: 0.7600 - val_accuracy: 0.9474 - val_loss: 0.6599\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5781 - loss: 0.8403\n",
      "Epoch 94: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5927 - loss: 0.8444 - val_accuracy: 0.9298 - val_loss: 0.6504\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.7024\n",
      "Epoch 95: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7324 - loss: 0.7313 - val_accuracy: 0.9298 - val_loss: 0.6409\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6406 - loss: 0.8139\n",
      "Epoch 96: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6567 - loss: 0.7980 - val_accuracy: 0.9298 - val_loss: 0.6321\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6406 - loss: 0.7896\n",
      "Epoch 97: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.6371 - loss: 0.7896 - val_accuracy: 0.9298 - val_loss: 0.6241\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7422 - loss: 0.7150\n",
      "Epoch 98: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7141 - loss: 0.7294 - val_accuracy: 0.9298 - val_loss: 0.6159\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6953 - loss: 0.7188\n",
      "Epoch 99: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6710 - loss: 0.7460 - val_accuracy: 0.9298 - val_loss: 0.6075\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6484 - loss: 0.7783\n",
      "Epoch 100: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6436 - loss: 0.7832 - val_accuracy: 0.9474 - val_loss: 0.5998\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7578 - loss: 0.6961\n",
      "Epoch 101: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7428 - loss: 0.7019 - val_accuracy: 0.9474 - val_loss: 0.5910\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6172 - loss: 0.8246\n",
      "Epoch 102: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6175 - loss: 0.8216 - val_accuracy: 0.9474 - val_loss: 0.5820\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.6912\n",
      "Epoch 103: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6880 - loss: 0.7155 - val_accuracy: 0.9474 - val_loss: 0.5727\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7422 - loss: 0.6748\n",
      "Epoch 104: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7415 - loss: 0.6853 - val_accuracy: 0.9474 - val_loss: 0.5637\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7734 - loss: 0.6424\n",
      "Epoch 105: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7519 - loss: 0.6693 - val_accuracy: 0.9474 - val_loss: 0.5545\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7266 - loss: 0.6974\n",
      "Epoch 106: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7402 - loss: 0.6829 - val_accuracy: 0.9649 - val_loss: 0.5457\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6875 - loss: 0.7576\n",
      "Epoch 107: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6919 - loss: 0.7639 - val_accuracy: 0.9649 - val_loss: 0.5378\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.6875 - loss: 0.7240\n",
      "Epoch 108: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7076 - loss: 0.7012 - val_accuracy: 0.9649 - val_loss: 0.5299\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6641 - loss: 0.7361\n",
      "Epoch 109: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6645 - loss: 0.7349 - val_accuracy: 0.9649 - val_loss: 0.5219\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7031 - loss: 0.7521\n",
      "Epoch 110: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7010 - loss: 0.7498 - val_accuracy: 0.9649 - val_loss: 0.5142\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7734 - loss: 0.6431\n",
      "Epoch 111: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7794 - loss: 0.6442 - val_accuracy: 0.9649 - val_loss: 0.5059\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7188 - loss: 0.6982\n",
      "Epoch 112: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7298 - loss: 0.6925 - val_accuracy: 0.9649 - val_loss: 0.4976\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.6797 - loss: 0.7410\n",
      "Epoch 113: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7011 - loss: 0.7202 - val_accuracy: 0.9649 - val_loss: 0.4889\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7188 - loss: 0.7154\n",
      "Epoch 114: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7063 - loss: 0.7149 - val_accuracy: 0.9649 - val_loss: 0.4808\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7109 - loss: 0.6900\n",
      "Epoch 115: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.6997 - loss: 0.6987 - val_accuracy: 0.9649 - val_loss: 0.4733\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7109 - loss: 0.6569\n",
      "Epoch 116: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7311 - loss: 0.6425 - val_accuracy: 0.9649 - val_loss: 0.4663\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6328 - loss: 0.7562\n",
      "Epoch 117: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.6462 - loss: 0.7428 - val_accuracy: 0.9649 - val_loss: 0.4597\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7109 - loss: 0.7102\n",
      "Epoch 118: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7272 - loss: 0.6931 - val_accuracy: 0.9649 - val_loss: 0.4529\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.6719 - loss: 0.6978\n",
      "Epoch 119: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6710 - loss: 0.7052 - val_accuracy: 0.9649 - val_loss: 0.4464\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6719 - loss: 0.7014\n",
      "Epoch 120: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6828 - loss: 0.6757 - val_accuracy: 0.9649 - val_loss: 0.4401\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6953 - loss: 0.7102\n",
      "Epoch 121: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7024 - loss: 0.7027 - val_accuracy: 0.9649 - val_loss: 0.4343\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7266 - loss: 0.6796\n",
      "Epoch 122: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7324 - loss: 0.6741 - val_accuracy: 0.9825 - val_loss: 0.4290\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6953 - loss: 0.6646\n",
      "Epoch 123: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6788 - loss: 0.6835 - val_accuracy: 0.9825 - val_loss: 0.4242\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8047 - loss: 0.5726\n",
      "Epoch 124: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7820 - loss: 0.5905 - val_accuracy: 0.9825 - val_loss: 0.4178\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6797 - loss: 0.6995\n",
      "Epoch 125: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6893 - loss: 0.6911 - val_accuracy: 0.9825 - val_loss: 0.4116\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7422 - loss: 0.6326\n",
      "Epoch 126: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7415 - loss: 0.6186 - val_accuracy: 0.9825 - val_loss: 0.4055\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7344 - loss: 0.6514\n",
      "Epoch 127: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7232 - loss: 0.6541 - val_accuracy: 0.9825 - val_loss: 0.3996\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7109 - loss: 0.6152\n",
      "Epoch 128: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7115 - loss: 0.6279 - val_accuracy: 1.0000 - val_loss: 0.3944\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7656 - loss: 0.6142\n",
      "Epoch 129: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7532 - loss: 0.6174 - val_accuracy: 0.9825 - val_loss: 0.3900\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.7344 - loss: 0.6128\n",
      "Epoch 130: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7154 - loss: 0.6390 - val_accuracy: 0.9825 - val_loss: 0.3863\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7422 - loss: 0.6268\n",
      "Epoch 131: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7337 - loss: 0.6398 - val_accuracy: 0.9825 - val_loss: 0.3831\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7891 - loss: 0.5661\n",
      "Epoch 132: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7924 - loss: 0.5731 - val_accuracy: 0.9825 - val_loss: 0.3794\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8047 - loss: 0.5942\n",
      "Epoch 133: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8055 - loss: 0.5990 - val_accuracy: 1.0000 - val_loss: 0.3755\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7812 - loss: 0.5901\n",
      "Epoch 134: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7663 - loss: 0.6008 - val_accuracy: 0.9825 - val_loss: 0.3712\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7031 - loss: 0.6353\n",
      "Epoch 135: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6971 - loss: 0.6449 - val_accuracy: 0.9825 - val_loss: 0.3676\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7188 - loss: 0.6551\n",
      "Epoch 136: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7259 - loss: 0.6442 - val_accuracy: 0.9825 - val_loss: 0.3652\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7188 - loss: 0.6294\n",
      "Epoch 137: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7298 - loss: 0.6145 - val_accuracy: 0.9825 - val_loss: 0.3620\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7578 - loss: 0.6014\n",
      "Epoch 138: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7271 - loss: 0.6345 - val_accuracy: 0.9825 - val_loss: 0.3586\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7969 - loss: 0.6097\n",
      "Epoch 139: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7794 - loss: 0.6187 - val_accuracy: 0.9649 - val_loss: 0.3558\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.7578 - loss: 0.6146\n",
      "Epoch 140: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7624 - loss: 0.6230 - val_accuracy: 0.9649 - val_loss: 0.3528\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7188 - loss: 0.6304\n",
      "Epoch 141: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7102 - loss: 0.6355 - val_accuracy: 0.9649 - val_loss: 0.3500\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7578 - loss: 0.5417\n",
      "Epoch 142: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7428 - loss: 0.5723 - val_accuracy: 0.9649 - val_loss: 0.3464\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7109 - loss: 0.6136\n",
      "Epoch 143: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7193 - loss: 0.6047 - val_accuracy: 0.9649 - val_loss: 0.3426\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7734 - loss: 0.5624\n",
      "Epoch 144: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7794 - loss: 0.5596 - val_accuracy: 0.9649 - val_loss: 0.3385\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7812 - loss: 0.5372\n",
      "Epoch 145: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7624 - loss: 0.5559 - val_accuracy: 0.9649 - val_loss: 0.3344\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7109 - loss: 0.6325\n",
      "Epoch 146: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7233 - loss: 0.6196 - val_accuracy: 0.9649 - val_loss: 0.3303\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7266 - loss: 0.6147\n",
      "Epoch 147: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7206 - loss: 0.6254 - val_accuracy: 0.9649 - val_loss: 0.3271\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7734 - loss: 0.5751\n",
      "Epoch 148: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7794 - loss: 0.5633 - val_accuracy: 0.9649 - val_loss: 0.3239\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7734 - loss: 0.5602\n",
      "Epoch 149: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.7676 - loss: 0.5652 - val_accuracy: 0.9649 - val_loss: 0.3206\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.5657\n",
      "Epoch 150: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7598 - loss: 0.5606 - val_accuracy: 0.9825 - val_loss: 0.3168\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7656 - loss: 0.5832\n",
      "Epoch 151: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7493 - loss: 0.5954 - val_accuracy: 0.9825 - val_loss: 0.3131\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7578 - loss: 0.5694\n",
      "Epoch 152: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7585 - loss: 0.5737 - val_accuracy: 0.9825 - val_loss: 0.3094\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7812 - loss: 0.5159\n",
      "Epoch 153: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7585 - loss: 0.5463 - val_accuracy: 0.9649 - val_loss: 0.3055\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6875 - loss: 0.6487\n",
      "Epoch 154: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7076 - loss: 0.6229 - val_accuracy: 0.9649 - val_loss: 0.3028\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7734 - loss: 0.5679\n",
      "Epoch 155: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7755 - loss: 0.5662 - val_accuracy: 0.9649 - val_loss: 0.2999\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7891 - loss: 0.5490\n",
      "Epoch 156: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7924 - loss: 0.5410 - val_accuracy: 0.9649 - val_loss: 0.2962\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7266 - loss: 0.6414\n",
      "Epoch 157: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7285 - loss: 0.6250 - val_accuracy: 0.9649 - val_loss: 0.2924\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7578 - loss: 0.5543\n",
      "Epoch 158: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7663 - loss: 0.5374 - val_accuracy: 0.9649 - val_loss: 0.2888\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7969 - loss: 0.4794\n",
      "Epoch 159: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8107 - loss: 0.4722 - val_accuracy: 0.9649 - val_loss: 0.2849\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8359 - loss: 0.5521\n",
      "Epoch 160: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8237 - loss: 0.5495 - val_accuracy: 0.9649 - val_loss: 0.2811\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7734 - loss: 0.5757\n",
      "Epoch 161: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7794 - loss: 0.5811 - val_accuracy: 0.9649 - val_loss: 0.2780\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8047 - loss: 0.4686\n",
      "Epoch 162: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7898 - loss: 0.4881 - val_accuracy: 0.9649 - val_loss: 0.2749\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7344 - loss: 0.5859\n",
      "Epoch 163: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7311 - loss: 0.5996 - val_accuracy: 0.9649 - val_loss: 0.2726\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8438 - loss: 0.4493\n",
      "Epoch 164: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8381 - loss: 0.4466 - val_accuracy: 0.9649 - val_loss: 0.2700\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7969 - loss: 0.4684\n",
      "Epoch 165: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7950 - loss: 0.4757 - val_accuracy: 0.9649 - val_loss: 0.2669\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7812 - loss: 0.5866\n",
      "Epoch 166: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7741 - loss: 0.5604 - val_accuracy: 0.9649 - val_loss: 0.2641\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8203 - loss: 0.5064\n",
      "Epoch 167: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8146 - loss: 0.5179 - val_accuracy: 0.9825 - val_loss: 0.2614\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8672 - loss: 0.4632\n",
      "Epoch 168: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8577 - loss: 0.4743 - val_accuracy: 0.9825 - val_loss: 0.2586\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7500 - loss: 0.5520\n",
      "Epoch 169: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7794 - loss: 0.5176 - val_accuracy: 0.9825 - val_loss: 0.2555\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7969 - loss: 0.5325\n",
      "Epoch 170: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7911 - loss: 0.5346 - val_accuracy: 0.9649 - val_loss: 0.2527\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8281 - loss: 0.4707\n",
      "Epoch 171: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8172 - loss: 0.4821 - val_accuracy: 0.9649 - val_loss: 0.2499\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7266 - loss: 0.5654\n",
      "Epoch 172: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7245 - loss: 0.5728 - val_accuracy: 0.9649 - val_loss: 0.2485\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8203 - loss: 0.5258\n",
      "Epoch 173: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8185 - loss: 0.5278 - val_accuracy: 0.9825 - val_loss: 0.2477\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7578 - loss: 0.5434\n",
      "Epoch 174: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7742 - loss: 0.5273 - val_accuracy: 0.9825 - val_loss: 0.2469\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7969 - loss: 0.5232\n",
      "Epoch 175: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7872 - loss: 0.5300 - val_accuracy: 0.9825 - val_loss: 0.2464\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8047 - loss: 0.4772\n",
      "Epoch 176: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8094 - loss: 0.4712 - val_accuracy: 0.9825 - val_loss: 0.2448\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7422 - loss: 0.5779\n",
      "Epoch 177: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7494 - loss: 0.5667 - val_accuracy: 0.9825 - val_loss: 0.2422\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7969 - loss: 0.5706\n",
      "Epoch 178: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7872 - loss: 0.5776 - val_accuracy: 1.0000 - val_loss: 0.2395\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8516 - loss: 0.5030\n",
      "Epoch 179: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8446 - loss: 0.5089 - val_accuracy: 0.9825 - val_loss: 0.2367\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7969 - loss: 0.5280\n",
      "Epoch 180: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8029 - loss: 0.5162 - val_accuracy: 0.9825 - val_loss: 0.2343\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7422 - loss: 0.6027\n",
      "Epoch 181: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7650 - loss: 0.5670 - val_accuracy: 0.9825 - val_loss: 0.2318\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8125 - loss: 0.4995\n",
      "Epoch 182: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7885 - loss: 0.5194 - val_accuracy: 0.9825 - val_loss: 0.2290\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8203 - loss: 0.4344\n",
      "Epoch 183: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8185 - loss: 0.4624 - val_accuracy: 0.9825 - val_loss: 0.2274\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8047 - loss: 0.4762\n",
      "Epoch 184: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8016 - loss: 0.4849 - val_accuracy: 0.9825 - val_loss: 0.2259\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8281 - loss: 0.4792\n",
      "Epoch 185: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8329 - loss: 0.4728 - val_accuracy: 0.9825 - val_loss: 0.2242\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7891 - loss: 0.5175\n",
      "Epoch 186: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7728 - loss: 0.5328 - val_accuracy: 0.9825 - val_loss: 0.2231\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8047 - loss: 0.4696\n",
      "Epoch 187: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8094 - loss: 0.4549 - val_accuracy: 0.9825 - val_loss: 0.2220\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7734 - loss: 0.5050\n",
      "Epoch 188: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7872 - loss: 0.4781 - val_accuracy: 0.9825 - val_loss: 0.2203\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.5570\n",
      "Epoch 189: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7559 - loss: 0.5423 - val_accuracy: 0.9825 - val_loss: 0.2183\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8281 - loss: 0.4604\n",
      "Epoch 190: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.8211 - loss: 0.4649 - val_accuracy: 0.9825 - val_loss: 0.2171\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8516 - loss: 0.4276\n",
      "Epoch 191: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8250 - loss: 0.4465 - val_accuracy: 0.9825 - val_loss: 0.2166\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7656 - loss: 0.5399\n",
      "Epoch 192: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7611 - loss: 0.5393 - val_accuracy: 1.0000 - val_loss: 0.2169\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7812 - loss: 0.5393\n",
      "Epoch 193: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7781 - loss: 0.5241 - val_accuracy: 1.0000 - val_loss: 0.2175\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8047 - loss: 0.5212\n",
      "Epoch 194: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8016 - loss: 0.5208 - val_accuracy: 1.0000 - val_loss: 0.2183\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7344 - loss: 0.5717\n",
      "Epoch 195: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7428 - loss: 0.5497 - val_accuracy: 0.9825 - val_loss: 0.2185\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7109 - loss: 0.6180\n",
      "Epoch 196: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7311 - loss: 0.5872 - val_accuracy: 0.9825 - val_loss: 0.2183\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7578 - loss: 0.4929\n",
      "Epoch 197: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7703 - loss: 0.4831 - val_accuracy: 0.9825 - val_loss: 0.2178\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7578 - loss: 0.5358\n",
      "Epoch 198: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7546 - loss: 0.5308 - val_accuracy: 0.9825 - val_loss: 0.2172\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7578 - loss: 0.5039\n",
      "Epoch 199: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7585 - loss: 0.5150 - val_accuracy: 0.9825 - val_loss: 0.2173\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7891 - loss: 0.4814\n",
      "Epoch 200: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7964 - loss: 0.4648 - val_accuracy: 0.9825 - val_loss: 0.2175\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7734 - loss: 0.5334\n",
      "Epoch 201: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7911 - loss: 0.5215 - val_accuracy: 0.9825 - val_loss: 0.2171\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7109 - loss: 0.5535\n",
      "Epoch 202: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7311 - loss: 0.5350 - val_accuracy: 0.9825 - val_loss: 0.2164\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7578 - loss: 0.5298\n",
      "Epoch 203: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7663 - loss: 0.5261 - val_accuracy: 0.9825 - val_loss: 0.2153\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8047 - loss: 0.4746\n",
      "Epoch 204: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7898 - loss: 0.4841 - val_accuracy: 0.9825 - val_loss: 0.2140\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7969 - loss: 0.5317\n",
      "Epoch 205: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7990 - loss: 0.5084 - val_accuracy: 0.9825 - val_loss: 0.2129\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.4851\n",
      "Epoch 206: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7520 - loss: 0.4978 - val_accuracy: 0.9825 - val_loss: 0.2117\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8359 - loss: 0.4293\n",
      "Epoch 207: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8237 - loss: 0.4447 - val_accuracy: 0.9825 - val_loss: 0.2102\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7891 - loss: 0.5245\n",
      "Epoch 208: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7807 - loss: 0.5209 - val_accuracy: 0.9825 - val_loss: 0.2086\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8516 - loss: 0.4278\n",
      "Epoch 209: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8564 - loss: 0.4068 - val_accuracy: 0.9825 - val_loss: 0.2069\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7969 - loss: 0.4712\n",
      "Epoch 210: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7950 - loss: 0.4735 - val_accuracy: 0.9825 - val_loss: 0.2052\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7812 - loss: 0.5016\n",
      "Epoch 211: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7820 - loss: 0.4908 - val_accuracy: 0.9825 - val_loss: 0.2038\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7344 - loss: 0.5236\n",
      "Epoch 212: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7468 - loss: 0.5243 - val_accuracy: 0.9825 - val_loss: 0.2029\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7656 - loss: 0.5053\n",
      "Epoch 213: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7689 - loss: 0.4975 - val_accuracy: 0.9825 - val_loss: 0.2025\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7891 - loss: 0.4840\n",
      "Epoch 214: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7846 - loss: 0.4975 - val_accuracy: 0.9825 - val_loss: 0.2022\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8125 - loss: 0.5258\n",
      "Epoch 215: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8159 - loss: 0.5092 - val_accuracy: 0.9825 - val_loss: 0.2024\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7812 - loss: 0.5231\n",
      "Epoch 216: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7898 - loss: 0.5057 - val_accuracy: 0.9825 - val_loss: 0.2027\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7969 - loss: 0.5034\n",
      "Epoch 217: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8068 - loss: 0.4822 - val_accuracy: 0.9825 - val_loss: 0.2020\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8203 - loss: 0.4642\n",
      "Epoch 218: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8107 - loss: 0.4789 - val_accuracy: 0.9825 - val_loss: 0.2008\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7969 - loss: 0.4591\n",
      "Epoch 219: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7990 - loss: 0.4731 - val_accuracy: 0.9825 - val_loss: 0.2001\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8594 - loss: 0.4025\n",
      "Epoch 220: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8512 - loss: 0.4217 - val_accuracy: 0.9825 - val_loss: 0.1994\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8672 - loss: 0.3694\n",
      "Epoch 221: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8538 - loss: 0.3904 - val_accuracy: 0.9825 - val_loss: 0.1987\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8203 - loss: 0.4689\n",
      "Epoch 222: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8303 - loss: 0.4521 - val_accuracy: 0.9825 - val_loss: 0.1976\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.7969 - loss: 0.4787\n",
      "Epoch 223: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7990 - loss: 0.4749 - val_accuracy: 0.9825 - val_loss: 0.1962\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8516 - loss: 0.4038\n",
      "Epoch 224: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8446 - loss: 0.4043 - val_accuracy: 0.9825 - val_loss: 0.1947\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7969 - loss: 0.4169\n",
      "Epoch 225: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7833 - loss: 0.4714 - val_accuracy: 0.9825 - val_loss: 0.1937\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7578 - loss: 0.5529\n",
      "Epoch 226: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7624 - loss: 0.5542 - val_accuracy: 0.9825 - val_loss: 0.1936\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7891 - loss: 0.5148\n",
      "Epoch 227: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8003 - loss: 0.4917 - val_accuracy: 0.9825 - val_loss: 0.1935\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8125 - loss: 0.4787\n",
      "Epoch 228: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8042 - loss: 0.4878 - val_accuracy: 0.9825 - val_loss: 0.1934\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8281 - loss: 0.4696\n",
      "Epoch 229: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8290 - loss: 0.4681 - val_accuracy: 0.9825 - val_loss: 0.1934\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7578 - loss: 0.4842\n",
      "Epoch 230: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7742 - loss: 0.4817 - val_accuracy: 0.9825 - val_loss: 0.1934\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7734 - loss: 0.4730\n",
      "Epoch 231: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7911 - loss: 0.4561 - val_accuracy: 0.9825 - val_loss: 0.1932\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7812 - loss: 0.4637\n",
      "Epoch 232: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7937 - loss: 0.4516 - val_accuracy: 0.9825 - val_loss: 0.1927\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7812 - loss: 0.4926\n",
      "Epoch 233: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7781 - loss: 0.4840 - val_accuracy: 0.9825 - val_loss: 0.1924\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7969 - loss: 0.4719\n",
      "Epoch 234: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8068 - loss: 0.4580 - val_accuracy: 0.9825 - val_loss: 0.1917\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8281 - loss: 0.4112\n",
      "Epoch 235: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8290 - loss: 0.4138 - val_accuracy: 0.9825 - val_loss: 0.1902\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7969 - loss: 0.4523\n",
      "Epoch 236: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7950 - loss: 0.4568 - val_accuracy: 0.9825 - val_loss: 0.1887\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7656 - loss: 0.4651\n",
      "Epoch 237: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7689 - loss: 0.4607 - val_accuracy: 0.9825 - val_loss: 0.1873\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7812 - loss: 0.4591\n",
      "Epoch 238: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7937 - loss: 0.4671 - val_accuracy: 0.9825 - val_loss: 0.1861\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8438 - loss: 0.3926\n",
      "Epoch 239: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8538 - loss: 0.3937 - val_accuracy: 0.9825 - val_loss: 0.1849\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8125 - loss: 0.3899\n",
      "Epoch 240: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8002 - loss: 0.4213 - val_accuracy: 0.9825 - val_loss: 0.1840\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8125 - loss: 0.4695\n",
      "Epoch 241: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8199 - loss: 0.4428 - val_accuracy: 0.9825 - val_loss: 0.1834\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7969 - loss: 0.4518\n",
      "Epoch 242: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8068 - loss: 0.4405 - val_accuracy: 0.9825 - val_loss: 0.1816\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7891 - loss: 0.4363\n",
      "Epoch 243: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8042 - loss: 0.4310 - val_accuracy: 0.9825 - val_loss: 0.1796\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7656 - loss: 0.5092\n",
      "Epoch 244: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.7768 - loss: 0.4919 - val_accuracy: 0.9825 - val_loss: 0.1773\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8281 - loss: 0.3557\n",
      "Epoch 245: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8133 - loss: 0.3694 - val_accuracy: 0.9825 - val_loss: 0.1749\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8203 - loss: 0.4469\n",
      "Epoch 246: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8146 - loss: 0.4391 - val_accuracy: 0.9825 - val_loss: 0.1724\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7969 - loss: 0.4543\n",
      "Epoch 247: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8107 - loss: 0.4433 - val_accuracy: 0.9825 - val_loss: 0.1703\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8125 - loss: 0.5258\n",
      "Epoch 248: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8199 - loss: 0.4970 - val_accuracy: 0.9825 - val_loss: 0.1683\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8203 - loss: 0.4702\n",
      "Epoch 249: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8146 - loss: 0.4961 - val_accuracy: 0.9825 - val_loss: 0.1675\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8203 - loss: 0.4238\n",
      "Epoch 250: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8185 - loss: 0.4501 - val_accuracy: 0.9825 - val_loss: 0.1677\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8125 - loss: 0.4237\n",
      "Epoch 251: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8316 - loss: 0.4123 - val_accuracy: 0.9825 - val_loss: 0.1682\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8047 - loss: 0.4246\n",
      "Epoch 252: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.8094 - loss: 0.4196 - val_accuracy: 0.9825 - val_loss: 0.1684\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8203 - loss: 0.3766\n",
      "Epoch 253: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8225 - loss: 0.3765 - val_accuracy: 0.9825 - val_loss: 0.1682\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8281 - loss: 0.4373\n",
      "Epoch 254: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8211 - loss: 0.4279 - val_accuracy: 0.9825 - val_loss: 0.1675\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8672 - loss: 0.3727\n",
      "Epoch 255: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8577 - loss: 0.3783 - val_accuracy: 0.9825 - val_loss: 0.1660\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8359 - loss: 0.4187\n",
      "Epoch 256: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8434 - loss: 0.4144 - val_accuracy: 0.9825 - val_loss: 0.1648\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7812 - loss: 0.4979\n",
      "Epoch 257: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7781 - loss: 0.4801 - val_accuracy: 0.9825 - val_loss: 0.1638\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8281 - loss: 0.4523\n",
      "Epoch 258: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8133 - loss: 0.4637 - val_accuracy: 0.9825 - val_loss: 0.1632\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8594 - loss: 0.3551\n",
      "Epoch 259: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8433 - loss: 0.4053 - val_accuracy: 0.9825 - val_loss: 0.1632\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8125 - loss: 0.4108\n",
      "Epoch 260: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8081 - loss: 0.4073 - val_accuracy: 0.9825 - val_loss: 0.1634\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8750 - loss: 0.4205\n",
      "Epoch 261: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8681 - loss: 0.4327 - val_accuracy: 0.9825 - val_loss: 0.1636\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8203 - loss: 0.4552\n",
      "Epoch 262: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8068 - loss: 0.4771 - val_accuracy: 0.9825 - val_loss: 0.1636\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8125 - loss: 0.4105\n",
      "Epoch 263: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8120 - loss: 0.4246 - val_accuracy: 0.9825 - val_loss: 0.1640\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8906 - loss: 0.3494\n",
      "Epoch 264: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8773 - loss: 0.3843 - val_accuracy: 0.9825 - val_loss: 0.1647\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8438 - loss: 0.4194\n",
      "Epoch 265: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8499 - loss: 0.4084 - val_accuracy: 0.9825 - val_loss: 0.1656\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7891 - loss: 0.4421\n",
      "Epoch 266: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7964 - loss: 0.4416 - val_accuracy: 0.9825 - val_loss: 0.1658\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8047 - loss: 0.4318\n",
      "Epoch 267: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8055 - loss: 0.4353 - val_accuracy: 0.9825 - val_loss: 0.1661\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7812 - loss: 0.5176\n",
      "Epoch 268: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7977 - loss: 0.4909 - val_accuracy: 0.9825 - val_loss: 0.1661\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8281 - loss: 0.4534\n",
      "Epoch 269: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8133 - loss: 0.4744 - val_accuracy: 0.9825 - val_loss: 0.1660\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7969 - loss: 0.4472\n",
      "Epoch 270: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7911 - loss: 0.4609 - val_accuracy: 0.9825 - val_loss: 0.1660\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7969 - loss: 0.4515\n",
      "Epoch 271: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7833 - loss: 0.4698 - val_accuracy: 0.9825 - val_loss: 0.1670\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7891 - loss: 0.4710\n",
      "Epoch 272: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.8042 - loss: 0.4737 - val_accuracy: 0.9825 - val_loss: 0.1682\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8516 - loss: 0.3723\n",
      "Epoch 273: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8603 - loss: 0.3694 - val_accuracy: 0.9825 - val_loss: 0.1683\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8281 - loss: 0.4372\n",
      "Epoch 274: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8251 - loss: 0.4467 - val_accuracy: 0.9825 - val_loss: 0.1684\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8359 - loss: 0.3789\n",
      "Epoch 275: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8512 - loss: 0.3831 - val_accuracy: 0.9825 - val_loss: 0.1683\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7578 - loss: 0.5149\n",
      "Epoch 276: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7742 - loss: 0.4951 - val_accuracy: 0.9825 - val_loss: 0.1681\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8281 - loss: 0.4349\n",
      "Epoch 277: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8290 - loss: 0.4323 - val_accuracy: 0.9825 - val_loss: 0.1684\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8594 - loss: 0.3818\n",
      "Epoch 278: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.8394 - loss: 0.4035 - val_accuracy: 0.9825 - val_loss: 0.1688\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7812 - loss: 0.4733\n",
      "Epoch 279: saving model to model/gesture_classifier/gesture_classifier.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7937 - loss: 0.4461 - val_accuracy: 0.9825 - val_loss: 0.1693\n",
      "Epoch 279: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cc1fe3e3d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.1657\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      1.00      1.00        26\n",
      "           2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.98        57\n",
      "   macro avg       0.98      0.98      0.98        57\n",
      "weighted avg       0.98      0.98      0.98        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/gesture_classifier/saved_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/gesture_classifier/saved_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'model/gesture_classifier/saved_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_layer_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1976362849504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1976362845632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1976362848800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1976362847216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1976362845280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1976362848448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export(\"model/gesture_classifier/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"model/gesture_classifier/saved_model\")\n",
    "tflite_model = converter.convert()\n",
    "with open(tflite_save_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\litvg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mset_tensor(input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], np\u001b[38;5;241m.\u001b[39marray([\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]))\n",
      "File \u001b[1;32mc:\\Users\\litvg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\litvg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
